{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_tutorial_1-2","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2SjM-Hu5S8cD","colab_type":"text"},"source":["#AUTOGRAD: 자동 미분\n","\n","PyTorch의 모든 신경망의 중심에는 autograd 패키지가 있다. autograd 패키지는 Tensor의 모든 연산에 대해 자동 미분을 제공한다. 순전파(forward) 단계에서는 수행하는 모든 연산을 기억하고, 역전파(backward)에서는 연산들을 replay한다. "]},{"cell_type":"markdown","metadata":{"id":"ewJDFaQcTXCp","colab_type":"text"},"source":["<br/>\n","\n","**tensor를 생성하고 requires_grad=True를 설정하여 연산을 기록합니다.**"]},{"cell_type":"code","metadata":{"id":"DqBGkC8bStkr","colab_type":"code","outputId":"bb3f5366-f203-44e3-ce7c-8ee9ab7ed104","executionInfo":{"status":"ok","timestamp":1565878597905,"user_tz":-540,"elapsed":1268,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import torch\n","\n","x = torch.ones(2,2, requires_grad=True)\n","print(x)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l-o2tj6zS74k","colab_type":"text"},"source":["<br/>\n","\n","**tensor에 연산을 수행합니다.**"]},{"cell_type":"code","metadata":{"id":"v_G_6OtrTze7","colab_type":"code","outputId":"2b3f8b71-eb07-4758-e4a1-c22a72decd2f","executionInfo":{"status":"ok","timestamp":1565878597906,"user_tz":-540,"elapsed":1258,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["y = x + 2\n","print(y)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RS46lrLvVWWE","colab_type":"text"},"source":["<br/>\n","\n","**y는 연산의 결과로 생성된 것이므로 grad_fn을 갖습니다. grad_fn은 미분값을 계산하는 함수에 대한 정보를 말합니다.** "]},{"cell_type":"code","metadata":{"id":"op0miNjLVWdo","colab_type":"code","outputId":"6a118178-34e5-4274-847e-2cd4e1c90420","executionInfo":{"status":"ok","timestamp":1565878597907,"user_tz":-540,"elapsed":1251,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(y.grad_fn)\n","print(y.grad)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["<AddBackward0 object at 0x7f63bcef0550>\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jpG-wPfbT2GX","colab_type":"text"},"source":["<br/>\n","\n","**y에 다른 연산을 수행합니다.**"]},{"cell_type":"code","metadata":{"id":"EXCKEq1sT09S","colab_type":"code","outputId":"c3772694-0ac5-4654-aa67-17f1bc39e1bb","executionInfo":{"status":"ok","timestamp":1565878597910,"user_tz":-540,"elapsed":1247,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["z = y * y * 3\n","out = z.mean()\n","\n","print(z, out)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bjH-bt-MUMLB","colab_type":"text"},"source":["<br/>\n","\n","**.require_grad_(...)는 기존 Tensor의 requires_grad값을 바꿔치기(in-place)하여 변경합니다. 입력값이 지정되지 않으면 기본값은 False입니다.**"]},{"cell_type":"code","metadata":{"id":"yX-_f_AmUD56","colab_type":"code","outputId":"179e2637-13b8-41b4-b26e-66f10b3a83d4","executionInfo":{"status":"ok","timestamp":1565878597910,"user_tz":-540,"elapsed":1238,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["a = torch.randn(2,2)\n","a = ((a * 3) / (a - 1))\n","print(a.requires_grad)\n","a.requires_grad_(True)\n","print(a.requires_grad)\n","b = (a * a).sum()\n","print(b.grad_fn)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["False\n","True\n","<SumBackward0 object at 0x7f637148ee80>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BgC_c0NHXvX_","colab_type":"text"},"source":["<br/><br/><br/>\n","\n","## 변화도(Gradient)\n","\n","<br/><br/>\n","이제 역전파(backprop)을 해보겠습니다. out은 하나의 스칼라 값만 가지고 있기 때문에, out.backward()는 out.backward(torch.tensor(1.))과 동일합니다."]},{"cell_type":"code","metadata":{"id":"v0Tk0RiFUdDH","colab_type":"code","colab":{}},"source":["out.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0sXE2clX8Te","colab_type":"text"},"source":["<br/>\n","\n","변화도 d(out)/dx를 출력합니다."]},{"cell_type":"code","metadata":{"id":"Y43uwIvkX54L","colab_type":"code","outputId":"038751d9-30f1-4b8e-e71f-2855a00e5033","executionInfo":{"status":"ok","timestamp":1565878597912,"user_tz":-540,"elapsed":1229,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(x.grad)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8jh4y56TZAFj","colab_type":"text"},"source":["<br/>\n","\n","**grad는 data가 거쳐온 layer에 대한 미분값이 축적되는 것을 말합니다.**\n","\n","<br/>\n","\n","이처럼 torch.autograd는 벡터-Jacobian 곱을 계싼하는 엔진입니다. "]},{"cell_type":"code","metadata":{"id":"MxnL4O9eYDo6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9b6eb49f-6c68-4b4e-a35f-bbd9c99a0ac7","executionInfo":{"status":"ok","timestamp":1565879290533,"user_tz":-540,"elapsed":939,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}}},"source":["x = torch.randn(3, requires_grad=True)\n","\n","y = x * 2\n","while y.data.norm() < 1000:  #data.norm은 norm2를 의미\n","  y = y * 2\n","\n","print(y)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([ 355.6519, 1157.0955,  221.1868], grad_fn=<MulBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hlLdRZ04r-AM","colab_type":"text"},"source":["<br/>\n","\n","tensor가 스칼라이면, backward()의 인자를 기록할 필요가 없습니다. 그러나 여러개의 값들을 가진경우, 일치하는 형태의 텐서 인자를 열거해야 합니다. 이 경우 y는 더 이상 스칼라 값이 아닙니다. torch.autograd는 전체 야코비안을 직접 계산할 수는 없지만, 벡터-야코비안 곱은 간단히 backward에 해당 벡터를 인자로 제공하여 얻을 수 있습니다."]},{"cell_type":"code","metadata":{"id":"bBVpmtJgoutW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6e2b80e5-606f-4339-d8f4-157ce88a0008","executionInfo":{"status":"ok","timestamp":1565879762001,"user_tz":-540,"elapsed":756,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}}},"source":["v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n","y.backward(v)\n","\n","print(x.grad)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"etdpOY__tQ8V","colab_type":"text"},"source":["<br/>\n","\n","또한 with torch.no_grad(): 로 코드 블록을 감싸서 autograd가 .requires_grad=True인 Tensor들의 연산 기록을 추적하는 것을 멈출 수 있습니다."]},{"cell_type":"code","metadata":{"id":"KTRwfvzstPj3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"da272754-90bf-4b1d-8747-7d6ea432c3c1","executionInfo":{"status":"ok","timestamp":1565879843092,"user_tz":-540,"elapsed":936,"user":{"displayName":"­허성실[컴퓨터공학부]","photoUrl":"","userId":"01070606707579909410"}}},"source":["print(x.requires_grad)\n","print((x**2).requires_grad)\n","\n","with torch.no_grad():\n","  print((x**2).requires_grad)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["True\n","True\n","False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nA367KCntZvo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
