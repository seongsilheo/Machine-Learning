{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet\n",
    "복잡한 머신러닝 모델을 학습하려면 엄청난 양의 데이터가 필요하다! 대부분 데이터셋은 적어도 수십만 개의 데이터를 제공한다.\n",
    "\n",
    "엄청난 양의 데이터를 한번에 학습시키기에는 너무 느리고, 하드웨어적으로 불가능하다. 어떻게 할까?\n",
    "\n",
    "## Minibatch Gradient Descent\n",
    "\n",
    "전체 데이터를 균일하게 나눠서 학습하자!\n",
    "이는 업데이트를 좀더 빠르게 할 수 있으나, 전체 데이터를 쓰지 않아서 잘못된 방향으로 업데이트를 할 수 도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):  #torch.utils.data.Datset 상속\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    def __len__(self):  #이 데이터셋으 치오 데이터 수\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):  #어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터 반환\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_Data[idx])\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=2, #minibatch의 크기, 통상적으로 2의 제곱수로 설정(16,32,64,128,256,512 ...)\n",
    "    shuffle=True) # epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_epochs = 20\n",
    "\n",
    "#for epoch in range(np_epochs + 1):\n",
    "    #for batch_idx, samples in enumerate(dataloader):\n",
    "        #x_train, y_train = samples\n",
    "\n",
    "        #H(x) 계산\n",
    "        #prediction = model(x_train) \n",
    "    \n",
    "        # cost 계산\n",
    "        #cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "        # cost로 H(x) 개선\n",
    "        #optimizer.zero_grad()\n",
    "        #cost.backward()\n",
    "        #optimizer.step()\n",
    "    \n",
    "        #print('Epoch {:4d}/{} Batch {}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, np_epochs, batch_idx+1, len(dataloader), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
