{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.5\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "w1 = torch.nn.Parameter(torch.Tensor(784, 30)).to(device)\n",
    "b1 = torch.nn.Parameter(torch.Tensor(30)).to(device)\n",
    "w2 = torch.nn.Parameter(torch.Tensor(30, 10)).to(device)\n",
    "b2 = torch.nn.Parameter(torch.Tensor(10)).to(device)\n",
    "\n",
    "#nn.linear 2개 사용한 것과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.0955,  0.6607,  0.0665,  0.6106,  0.8472, -0.1985,  0.2002,  0.4387,\n",
       "        -0.5780, -0.4606], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(w1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(w2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):  #derivative of the sigmoid function\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n",
      "923\n",
      "928\n",
      "938\n",
      "928\n",
      "931\n",
      "935\n",
      "929\n",
      "934\n",
      "932\n"
     ]
    }
   ],
   "source": [
    "X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)[:1000]\n",
    "Y_test = mnist_test.test_labels.to(device)[:1000]\n",
    "i = 0\n",
    "while not i == 10000:\n",
    "    for X, Y in data_loader:\n",
    "        i += 1\n",
    "        \n",
    "        # forward\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = torch.zeros((batch_size, 10)).scatter_(1, Y.unsqueeze(1), 1).to(device) #one-hot으로 바꿈\n",
    "        l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "        a1 = sigmoid(l1)\n",
    "        l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "        y_pred = sigmoid(l2)\n",
    "        # Error = 1/2(Y - y_pred)^2 -> 미분하면 y_pred -Y \n",
    "        diff = y_pred - Y\n",
    "        \n",
    "        # Back prop (chain rule)\n",
    "        d_l2 = diff * sigmoid_prime(l2)\n",
    "        d_b2 = d_l2\n",
    "        d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
    "        \n",
    "        d_a1 = torch.matmul(d_l2, torch.transpose(w2, 0, 1))\n",
    "        d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "        d_b1 = d_l1\n",
    "        d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
    "\n",
    "        w1 = w1 - learning_rate * d_w1\n",
    "        b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "        w2 = w2 - learning_rate * d_w2\n",
    "        b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            l1 = torch.add(torch.matmul(X_test, w1), b1)\n",
    "            a1 = sigmoid(l1)\n",
    "            l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "            y_pred = sigmoid(l2)\n",
    "            acct_mat = torch.argmax(y_pred, 1) == Y_test\n",
    "            \n",
    "            acct_res = acct_mat.sum()\n",
    "            print(acct_res.item())\n",
    "\n",
    "        if i == 10000:\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor- nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.698509693145752\n",
      "100 0.6929240226745605\n",
      "200 0.6923138499259949\n",
      "300 0.6899295449256897\n",
      "400 0.6721627712249756\n",
      "500 0.5749703049659729\n",
      "600 0.3096465766429901\n",
      "700 0.09439206123352051\n",
      "800 0.05063152313232422\n",
      "900 0.033998824656009674\n",
      "1000 0.02542046457529068\n",
      "1100 0.020230667665600777\n",
      "1200 0.016768211498856544\n",
      "1300 0.014300236478447914\n",
      "1400 0.012455277144908905\n",
      "1500 0.01102551631629467\n",
      "1600 0.009885938838124275\n",
      "1700 0.008956958539783955\n",
      "1800 0.008185474202036858\n",
      "1900 0.007534815929830074\n",
      "2000 0.006978826597332954\n",
      "2100 0.006498412694782019\n",
      "2200 0.00607915548607707\n",
      "2300 0.005710202734917402\n",
      "2400 0.005383028648793697\n",
      "2500 0.005090941675007343\n",
      "2600 0.004828638397157192\n",
      "2700 0.0045917825773358345\n",
      "2800 0.004376884084194899\n",
      "2900 0.004181038588285446\n",
      "3000 0.004001826513558626\n",
      "3100 0.003837218740954995\n",
      "3200 0.003685502801090479\n",
      "3300 0.003545236773788929\n",
      "3400 0.0034151594154536724\n",
      "3500 0.003294220194220543\n",
      "3600 0.00318150338716805\n",
      "3700 0.0030761698726564646\n",
      "3800 0.002977558644488454\n",
      "3900 0.0028849958907812834\n",
      "4000 0.0027980308514088392\n",
      "4100 0.0027160942554473877\n",
      "4200 0.002638797042891383\n",
      "4300 0.0025657338555902243\n",
      "4400 0.0024965903721749783\n",
      "4500 0.0024310522712767124\n",
      "4600 0.0023688345681875944\n",
      "4700 0.002309712814167142\n",
      "4800 0.0022534176241606474\n",
      "4900 0.0021998288575559855\n",
      "5000 0.0021486924961209297\n",
      "5100 0.0020998583640903234\n",
      "5200 0.002053176984190941\n",
      "5300 0.002008573617786169\n",
      "5400 0.001965794013813138\n",
      "5500 0.0019247930031269789\n",
      "5600 0.001885495614260435\n",
      "5700 0.0018477228004485369\n",
      "5800 0.0018114594276994467\n",
      "5900 0.0017765555530786514\n",
      "6000 0.001742966822348535\n",
      "6100 0.0017106481827795506\n",
      "6200 0.001679479843005538\n",
      "6300 0.0016494172159582376\n",
      "6400 0.0016204002313315868\n",
      "6500 0.001592384185642004\n",
      "6600 0.0015653092414140701\n",
      "6700 0.0015391604974865913\n",
      "6800 0.001513877883553505\n",
      "6900 0.0014893572079017758\n",
      "7000 0.0014656430575996637\n",
      "7100 0.0014426754787564278\n",
      "7200 0.00142041000071913\n",
      "7300 0.0013987866695970297\n",
      "7400 0.001377865206450224\n",
      "7500 0.0013574814656749368\n",
      "7600 0.0013377695577219129\n",
      "7700 0.0013185653369873762\n",
      "7800 0.0012999136233702302\n",
      "7900 0.0012818141840398312\n",
      "8000 0.0012641778448596597\n",
      "8100 0.001247019157744944\n",
      "8200 0.001230338355526328\n",
      "8300 0.001214060583151877\n",
      "8400 0.0011982156429439783\n",
      "8500 0.0011827739654108882\n",
      "8600 0.0011677502188831568\n",
      "8700 0.001153054996393621\n",
      "8800 0.001138777588494122\n",
      "8900 0.0011248436057940125\n",
      "9000 0.001111223129555583\n",
      "9100 0.0010979458456858993\n",
      "9200 0.0010849671671167016\n",
      "9300 0.0010722721926867962\n",
      "9400 0.001059905393049121\n",
      "9500 0.0010477924952283502\n",
      "9600 0.0010359481675550342\n",
      "9700 0.0010243576252833009\n",
      "9800 0.0010130655718967319\n",
      "9900 0.0010020271874964237\n",
      "10000 0.000991197768598795\n"
     ]
    }
   ],
   "source": [
    "#nn layers\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True)  # MLP\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "# define cost/Loss * optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/Loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor-nn-wide-deep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7792053818702698\n",
      "100 0.6931605339050293\n",
      "200 0.6931594610214233\n",
      "300 0.6931584477424622\n",
      "400 0.693157434463501\n",
      "500 0.6931564807891846\n",
      "600 0.6931555271148682\n",
      "700 0.6931545734405518\n",
      "800 0.6931536197662354\n",
      "900 0.6931527853012085\n",
      "1000 0.6931518912315369\n",
      "1100 0.6931511163711548\n",
      "1200 0.6931502223014832\n",
      "1300 0.6931493878364563\n",
      "1400 0.6931484937667847\n",
      "1500 0.6931477189064026\n",
      "1600 0.6931468844413757\n",
      "1700 0.6931460499763489\n",
      "1800 0.6931451559066772\n",
      "1900 0.6931443214416504\n",
      "2000 0.693143367767334\n",
      "2100 0.6931425333023071\n",
      "2200 0.6931415796279907\n",
      "2300 0.6931406855583191\n",
      "2400 0.6931396722793579\n",
      "2500 0.693138599395752\n",
      "2600 0.6931375861167908\n",
      "2700 0.6931365728378296\n",
      "2800 0.6931354403495789\n",
      "2900 0.6931343078613281\n",
      "3000 0.6931330561637878\n",
      "3100 0.6931318044662476\n",
      "3200 0.6931304335594177\n",
      "3300 0.6931289434432983\n",
      "3400 0.6931275129318237\n",
      "3500 0.69312584400177\n",
      "3600 0.6931241750717163\n",
      "3700 0.6931222677230835\n",
      "3800 0.6931203603744507\n",
      "3900 0.6931183338165283\n",
      "4000 0.6931160092353821\n",
      "4100 0.6931135654449463\n",
      "4200 0.6931108236312866\n",
      "4300 0.693108081817627\n",
      "4400 0.6931048631668091\n",
      "4500 0.6931014657020569\n",
      "4600 0.6930976510047913\n",
      "4700 0.6930934190750122\n",
      "4800 0.6930887699127197\n",
      "4900 0.6930835247039795\n",
      "5000 0.693077802658081\n",
      "5100 0.6930712461471558\n",
      "5200 0.6930638551712036\n",
      "5300 0.6930554509162903\n",
      "5400 0.6930457353591919\n",
      "5500 0.6930345296859741\n",
      "5600 0.6930215358734131\n",
      "5700 0.693006157875061\n",
      "5800 0.6929879188537598\n",
      "5900 0.6929659247398376\n",
      "6000 0.692939043045044\n",
      "6100 0.692905843257904\n",
      "6200 0.6928638219833374\n",
      "6300 0.6928095817565918\n",
      "6400 0.6927376389503479\n",
      "6500 0.6926389932632446\n",
      "6600 0.6924981474876404\n",
      "6700 0.6922856569290161\n",
      "6800 0.6919410228729248\n",
      "6900 0.6913208365440369\n",
      "7000 0.6900092363357544\n",
      "7100 0.6863319277763367\n",
      "7200 0.6669495105743408\n",
      "7300 0.4333575367927551\n",
      "7400 0.016813993453979492\n",
      "7500 0.00692081730812788\n",
      "7600 0.0041800448670983315\n",
      "7700 0.0029454994946718216\n",
      "7800 0.002254508901387453\n",
      "7900 0.0018167304806411266\n",
      "8000 0.001516081509180367\n",
      "8100 0.001297705341130495\n",
      "8200 0.0011322916252538562\n",
      "8300 0.0010029281256720424\n",
      "8400 0.0008990707574412227\n",
      "8500 0.0008140600984916091\n",
      "8600 0.0007431935518980026\n",
      "8700 0.0006832622457295656\n",
      "8800 0.000631938106380403\n",
      "8900 0.0005875348579138517\n",
      "9000 0.0005487694288603961\n",
      "9100 0.0005146422190591693\n",
      "9200 0.0004843476344831288\n",
      "9300 0.00045733375009149313\n",
      "9400 0.0004330636584199965\n",
      "9500 0.0004111346206627786\n",
      "9600 0.0003912930842489004\n",
      "9700 0.0003732109325937927\n",
      "9800 0.00035663467133417726\n",
      "9900 0.00034144497476518154\n",
      "10000 0.0003274480113759637\n"
     ]
    }
   ],
   "source": [
    "#nn layers\n",
    "linear1 = torch.nn.Linear(2, 10, bias=True)  # MLP\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
    "\n",
    "# define cost/Loss * optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/Loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
